from model import *

# è¿è¡Œ Optuna è¶…å‚æ•°ä¼˜åŒ–
best_params = load_best_hyperparams()
if best_params:
    print("ğŸ“Œ è½½å…¥çš„æœ€ä¼˜è¶…å‚æ•°ï¼š", best_params)
    
else:
    print("ğŸ¯ å–µå‘œ~ å¼€å§‹å¯»æ‰¾æœ€æ£’çš„è¶…å‚æ•°ç»„åˆï¼")
    study = optuna.create_study(direction="minimize")
    study.optimize(objective, n_trials=20)

    # è·å–æœ€ä½³è¶…å‚æ•°å¹¶ä¿å­˜
    best_params = study.best_params
    print(f"ğŸ† å–µå–µæ‰¾åˆ°æœ€ä½³å‚æ•°å•¦ï¼{best_params}")
    save_best_hyperparams(best_params)


# è®­ç»ƒæœ€ç»ˆæ¨¡å‹
final_model = RegressionModel(input_size=X.shape[1], hidden_size=best_params["hidden_size"], num_layers=best_params["num_layers"]).to(device)
final_optimizer = optim.Adam(final_model.parameters(), lr=best_params["lr"])
final_criterion = nn.MSELoss()
train_loader = data.DataLoader(train_dataset, batch_size=best_params["batch_size"], shuffle=True)
val_loader = data.DataLoader(val_dataset, batch_size=best_params["batch_size"], shuffle=False)

best_val_loss = float("inf")
early_stopping = EarlyStopping(patience=10)

print("ğŸš€ å¼€å§‹æœ€ç»ˆè®­ç»ƒå–µï¼")
for epoch in range(100):
    final_model.train()
    for batch_X, batch_y in train_loader:
        batch_X, batch_y = batch_X.to(device), batch_y.to(device)
        final_optimizer.zero_grad()
        outputs = final_model(batch_X)
        loss = final_criterion(outputs, batch_y)
        loss.backward()
        final_optimizer.step()

    final_model.eval()
    val_loss = 0
    with torch.no_grad():
        for batch_X, batch_y in val_loader:
            batch_X, batch_y = batch_X.to(device), batch_y.to(device)
            outputs = final_model(batch_X)
            val_loss += final_criterion(outputs, batch_y).item()
    val_loss /= len(val_loader)

    print(f"ğŸ“Š æœ€ç»ˆæ¨¡å‹ - Epoch {epoch+1}: éªŒè¯æŸå¤± {val_loss:.6f}")

    if val_loss < best_val_loss:
        best_val_loss = val_loss
        torch.save(final_model.state_dict(), "best_model.pth")
        print("ğŸ’¾ å–µå–µå­˜å¥½äº†æœ€æ£’çš„æ¨¡å‹ï¼")

    if early_stopping.step(val_loss):
        print("ğŸ’¤ æ—©åœè§¦å‘ï¼å–µä¸ç»ƒäº†ï¼")
        break

print(f"ğŸ‰ æœ€ç»ˆè®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}ï¼Œå–µå‘œ~ï¼(â‰§â–½â‰¦)âœ¨")
