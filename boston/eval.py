from sklearn.metrics import r2_score, mean_squared_error
import numpy as np
import torch
from model import *

best_params = load_best_hyperparams()


def evaluate_model(model, dataloader, criterion):
    """è¯„ä¼°æ¨¡å‹ï¼Œè®¡ç®— RÂ²ã€MSE å’Œ RMSE"""
    model.eval()  # è¿›å…¥è¯„ä¼°æ¨¡å¼
    all_preds, all_targets = [], []
    total_loss = 0

    with torch.no_grad():
        for batch_X, batch_y in dataloader:
            batch_X, batch_y = batch_X.to(device), batch_y.to(device)
            outputs = model(batch_X)

            loss = criterion(outputs, batch_y)
            total_loss += loss.item()

            all_preds.extend(outputs.cpu().numpy().flatten())
            all_targets.extend(batch_y.cpu().numpy().flatten())

    mse = mean_squared_error(all_targets, all_preds)
    rmse = np.sqrt(mse)
    r2 = r2_score(all_targets, all_preds)

    print("ğŸ“Šâœ¨ æ¨¡å‹è¯„ä¼°å®Œæ¯•å–µï¼æ¥çœ‹çœ‹ç»“æœå§ï¼(à¸…^â€¢Ï‰â€¢^à¸…)")
    print(f"ğŸ”¹ MSEï¼ˆå‡æ–¹è¯¯å·®ï¼‰: {mse:.6f}")
    print(f"ğŸ”¹ RMSEï¼ˆå‡æ–¹æ ¹è¯¯å·®ï¼‰: {rmse:.6f}")
    print(f"ğŸ”¹ RÂ²ï¼ˆå†³å®šç³»æ•°ï¼‰: {r2:.6f} (RÂ² è¶Šæ¥è¿‘ 1 è¯´æ˜æ¨¡å‹æ‹Ÿåˆæ•ˆæœè¶Šå¥½å“¦ï¼)")

    return {"MSE": mse, "RMSE": rmse, "RÂ²": r2}

# åŠ è½½æœ€ä½³æ¨¡å‹
final_model = RegressionModel(input_size=X.shape[1], hidden_size=best_params["hidden_size"], num_layers=best_params["num_layers"]).to(device)
final_model.load_state_dict(torch.load("best_model.pth"))
final_model.eval()

# è¯„ä¼°æ¨¡å‹
test_loader = data.DataLoader(val_dataset, batch_size=best_params["batch_size"], shuffle=False)
metrics = evaluate_model(final_model, test_loader, nn.MSELoss())
